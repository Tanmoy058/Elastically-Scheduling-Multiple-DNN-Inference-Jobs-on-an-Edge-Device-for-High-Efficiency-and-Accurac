{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import sys\n",
    "import torch  \n",
    "import gym\n",
    "import queue\n",
    "import numpy as np  \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "\n",
    "FLOAT_BYTE_SIZE = 8\n",
    "HOST_CPU_FLOP = 62000000000\n",
    "MAX_MEMORY = 0\n",
    "MEMORY_LEVELS = 30\n",
    "INVALID = -1\n",
    "INVALID_INCR = -0.0001\n",
    "BETA = 0.5\n",
    "GAMMA = 0.9\n",
    "WORKER_MEM = 165\n",
    "\n",
    "MAX_OP_PARAM = []\n",
    "MAX_ED_PARAM = []\n",
    "\n",
    "def init():\n",
    "    for i in range(5):\n",
    "        MAX_OP_PARAM.append(0.0)\n",
    "    for i in range(5):\n",
    "        MAX_ED_PARAM.append(0.0)\n",
    "\n",
    "\n",
    "init()\n",
    "\n",
    "def calc_level(mem):\n",
    "    #global MAX_MEMORY, MEMORY_LEVELS\n",
    "    interval = MAX_MEMORY/MEMORY_LEVELS\n",
    "    \n",
    "    if(mem<=0):\n",
    "            return 0\n",
    "\n",
    "    return int(mem/interval)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Computation_Graph:\n",
    "    \n",
    "    def __init__(self, filename, memoryfile):\n",
    "        \n",
    "        #batch size\n",
    "        #number of layers, number of connections\n",
    "        #for each layer\n",
    "            #layer name, layer_mem in MB, # of params in layer,  dimension2, dimensioon3, ...\n",
    "\n",
    "        fileReader = open(filename,'r')\n",
    "        memoryfile = open(memoryfile,'r')\n",
    "\n",
    "        #self.batch_size = int(fileReader.readline())\n",
    "        self.batch_size = 1\n",
    "\n",
    "        vertex, edge = (fileReader.readline().split())\n",
    "        self.num_layers = int(vertex)\n",
    "        self.num_connections = int(edge)\n",
    "\n",
    "        self.layer_estimated_mem = []\n",
    "        self.layer_estimated_float_op = [] \n",
    "        self.layer_output_shape = []\n",
    "        self.layer_name_to_idx_map = {}\n",
    "        self.layer_idx_to_name_map = {}\n",
    "        self.adj_list = []\n",
    "        self.rev_adj_list = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            \n",
    "            print(i)\n",
    "            self.adj_list.append([])\n",
    "            self.rev_adj_list.append([])\n",
    "            \n",
    "            layer_info = fileReader.readline().split() #layer_info is an array now\n",
    "            memory_info = memoryfile.readline().split()\n",
    "            \n",
    "            print(memory_info)\n",
    "            \n",
    "            self.layer_name_to_idx_map[layer_info[0]] = i\n",
    "            self.layer_idx_to_name_map[i] = layer_info[0]\n",
    "\n",
    "            self.layer_estimated_mem.append(float(memory_info[1])-WORKER_MEM)\n",
    "            global MAX_MEMORY\n",
    "            MAX_MEMORY = max(MAX_MEMORY,float(memory_info[1]))\n",
    "\n",
    "            self.layer_estimated_float_op.append(float(layer_info[1]))\n",
    "            \n",
    "            #this has to be rewritten\n",
    "            output_byte = self.batch_size*FLOAT_BYTE_SIZE #floating point number is 4 byte\n",
    "\n",
    "            #for k in range(3,len(layer_info)):\n",
    "                #output_byte = output_byte*(float(layer_info[k]))\n",
    "\n",
    "            #self.layer_output_shape.append(float(output_byte))\n",
    "            self.layer_output_shape.append(0.0)\n",
    "            #this has to be rewritten\n",
    "\n",
    "        for i in range(self.num_connections):\n",
    "            #this has to be rewritten\n",
    "            u,v,w = fileReader.readline().split()\n",
    "            self.adj_list[self.layer_name_to_idx_map[u]].append(self.layer_name_to_idx_map[v])\n",
    "            self.rev_adj_list[self.layer_name_to_idx_map[v]].append(self.layer_name_to_idx_map[u])\n",
    "            self.layer_output_shape[self.layer_name_to_idx_map[u]] = float(w)\n",
    "\n",
    "        #print(type(self.adj_list[0][0]))\n",
    "        #print(self.adj_list)\n",
    "        fileReader.close()\n",
    "\n",
    "    def print_info(self):\n",
    "        print(self.layer_estimated_mem)\n",
    "        print(self.layer_estimated_float_op)\n",
    "        print(self.layer_output_shape) \n",
    "        \n",
    "    def get_mem_required(self, layer_name, MB = 1):\n",
    "\n",
    "        val = self.layer_estimated_mem[self.layer_name_to_idx_map[layer_name]]\n",
    "        \n",
    "        if MB == 0:\n",
    "            return (float(val))*(1024.0*1024.0)\n",
    "\n",
    "        return val\n",
    "\n",
    "    def get_mem_level(self, layer_idx):\n",
    "\n",
    "        global MAX_MEMORY,MEMORY_LEVELS\n",
    "\n",
    "        interval = MAX_MEMORY/MEMORY_LEVELS\n",
    "\n",
    "        if(self.layer_estimated_mem[layer_idx]<=0):\n",
    "            return 0\n",
    "\n",
    "        return int(self.layer_estimated_mem[layer_idx]/interval)+1\n",
    "\n",
    "\n",
    "    def get_cpu_required(self, layer_name):\n",
    "\n",
    "        return self.layer_estimated_float_op[self.layer_name_to_idx_map[layer_name]]\n",
    "\n",
    "    def get_data_transferred(self, layer_u, layer_v):\n",
    "\n",
    "        u = self.layer_name_to_idx_map[layer_u]\n",
    "        v = self.layer_name_to_idx_map[layer_v]\n",
    "\n",
    "        if v in self.adj_list[u]:\n",
    "            return self.layer_output_shape[u]\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def toposort(self):\n",
    "        \n",
    "        topoReader = open(\"topo_out.txt\")\n",
    "        topo_order = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            v, level = topoReader.readline().split()\n",
    "            topo_order.append((int(v),int(level)))\n",
    "\n",
    "        return (1,topo_order)\n",
    "\n",
    "    def check_topo_sort(self):\n",
    "\n",
    "        acyclic,topo = self.toposort()\n",
    "\n",
    "        if(acyclic==1):\n",
    "\n",
    "            for v in topo:\n",
    "                print(self.layer_idx_to_name_map[v[0]])\n",
    "\n",
    "        else:\n",
    "            print('no topo exists')\n",
    "\n",
    "\n",
    "#sample input for testing one correctness\n",
    "# 30\n",
    "# 3 3\n",
    "# conv_1 20 10 28 28 1\n",
    "# conv_2 10 20 32 32 1\n",
    "# dense_1 100 10 128 128\n",
    "# conv_2 dense_1\n",
    "# conv_1 dense_1\n",
    "# conv_1 conv_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Device_Graph:\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        \n",
    "        #num_devices.. where devices connected in star topology\n",
    "        #name, num_flop, memory in MB\n",
    "\n",
    "        fileReader = open(filename,'r')\n",
    "        \n",
    "        device_no = int(fileReader.readline())\n",
    "        \n",
    "        self.num_devices = device_no\n",
    "        self.device_memory = []\n",
    "        self.device_flops = [] \n",
    "        self.device_name_to_idx_map = {}\n",
    "        self.device_idx_to_name_map = {}\n",
    "        self.bridge_bandwidth = [] #bandwidth to bridge\n",
    "        self.filename = filename\n",
    "\n",
    "        for i in range(device_no):\n",
    "            \n",
    "            edge_info = fileReader.readline().split()\n",
    "            \n",
    "            self.device_memory.append(float(edge_info[2])-WORKER_MEM)\n",
    "            global MAX_MEMORY\n",
    "            MAX_MEMORY = max(MAX_MEMORY,float(edge_info[2]))\n",
    "\n",
    "            self.device_flops.append(float(edge_info[1]))\n",
    "            \n",
    "            self.device_name_to_idx_map[edge_info[0]] = i\n",
    "            self.device_idx_to_name_map[i] = edge_info[0]\n",
    "\n",
    "        for i in range(device_no):\n",
    "            bw_master = float(fileReader.readline())\n",
    "            self.bridge_bandwidth.append(bw_master)\n",
    "        \n",
    "        #print(self.bridge_bandwidth)\n",
    "\n",
    "    def get_mem_level(self, device_idx):\n",
    "\n",
    "        interval = MAX_MEMORY/MEMORY_LEVELS\n",
    "\n",
    "        if(self.device_memory[device_idx]<=0):\n",
    "            return 0\n",
    "\n",
    "        return int(self.device_memory[device_idx]/interval)+1\n",
    "\n",
    "    def get_device_flop(self, device_idx):\n",
    "\n",
    "        return self.device_flops[device_idx]\n",
    "\n",
    "    def print_info(self):\n",
    "        print(self.device_memory)\n",
    "        print(self.device_flops)\n",
    "        print(self.bridge_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['conv_1', '1153.696']\n",
      "1\n",
      "['conv_2', '1929.888']\n",
      "2\n",
      "['pool_1', '545.7']\n",
      "3\n",
      "['conv_3', '1134.24']\n",
      "4\n",
      "['conv_4', '1264.288']\n",
      "5\n",
      "['pool_2', '390.9']\n",
      "6\n",
      "['conv_5', '654.1']\n",
      "7\n",
      "['conv_6', '664.9']\n",
      "8\n",
      "['conv_7', '543.1']\n",
      "9\n",
      "['pool_3', '363.7']\n",
      "10\n",
      "['conv_8', '498.178']\n",
      "11\n",
      "['conv_9', '740.3']\n",
      "12\n",
      "['conv_10', '740.9']\n",
      "13\n",
      "['pool_4', '305.3']\n",
      "14\n",
      "['conv_11', '640.4']\n",
      "15\n",
      "['conv_12', '695.9']\n",
      "16\n",
      "['conv_13', '670.5']\n",
      "17\n",
      "['pool_5', '283.9']\n",
      "18\n",
      "['flat_1', '200']\n",
      "19\n",
      "['dense_1', '630']\n",
      "20\n",
      "['dense_2', '670']\n",
      "21\n",
      "['dense_3', '324']\n",
      "[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22)]\n",
      "will place 0.0 now , requires 50176.0 flops , will tranx 50176.0 data , requires 8.0 level memory\n",
      "device 0 , has memory level 25.0 , will exec 0.0 operations , has 214.0 bw with bridge , has 898887170.0 flops\n",
      "device 1 , has memory level 13.0 , will exec 0.0 operations , has 129.0 bw with bridge , has 566135391.0 flops\n",
      "device 2 , has memory level 21.0 , will exec 0.0 operations , has 233.0 bw with bridge , has 388634270.0 flops\n",
      "device 3 , has memory level 13.0 , will exec 0.0 operations , has 178.0 bw with bridge , has 799591856.0 flops\n",
      "device 4 , has memory level 9.0 , will exec 0.0 operations , has 512.0 bw with bridge , has 765408594.0 flops\n",
      "device 5 , has memory level 27.0 , will exec 0.0 operations , has 467.0 bw with bridge , has 788913761.0 flops\n",
      "device 6 , has memory level 26.0 , will exec 0.0 operations , has 221.0 bw with bridge , has 879990765.0 flops\n",
      "device 7 , has memory level 26.0 , will exec 0.0 operations , has 855.0 bw with bridge , has 428789547.0 flops\n",
      "device 8 , has memory level 11.0 , will exec 0.0 operations , has 265.0 bw with bridge , has 738697649.0 flops\n",
      "\n",
      "will place 1.0 now , requires 50176.0 flops , will tranx 50176.0 data , requires 13.0 level memory\n",
      "device 0 , has memory level 18.0 , will exec 1.0 operations , has 214.0 bw with bridge , has 898887170.0 flops\n",
      "device 1 , has memory level 13.0 , will exec 0.0 operations , has 129.0 bw with bridge , has 566135391.0 flops\n",
      "device 2 , has memory level 21.0 , will exec 0.0 operations , has 233.0 bw with bridge , has 388634270.0 flops\n",
      "device 3 , has memory level 13.0 , will exec 0.0 operations , has 178.0 bw with bridge , has 799591856.0 flops\n",
      "device 4 , has memory level 9.0 , will exec 0.0 operations , has 512.0 bw with bridge , has 765408594.0 flops\n",
      "device 5 , has memory level 27.0 , will exec 0.0 operations , has 467.0 bw with bridge , has 788913761.0 flops\n",
      "device 6 , has memory level 26.0 , will exec 0.0 operations , has 221.0 bw with bridge , has 879990765.0 flops\n",
      "device 7 , has memory level 26.0 , will exec 0.0 operations , has 855.0 bw with bridge , has 428789547.0 flops\n",
      "device 8 , has memory level 11.0 , will exec 0.0 operations , has 265.0 bw with bridge , has 738697649.0 flops\n",
      "\n",
      " \n",
      "will place 2.0 now , requires 50176.0 flops , will tranx 12544.0 data , requires 3.0 level memory\n",
      "device 0 , has memory level 18.0 , will exec 1.0 operations , has 214.0 bw with bridge , has 898887170.0 flops\n",
      "device 1 , has memory level 0.0 , will exec 1.0 operations , has 129.0 bw with bridge , has 566135391.0 flops\n",
      "device 2 , has memory level 21.0 , will exec 0.0 operations , has 233.0 bw with bridge , has 388634270.0 flops\n",
      "device 3 , has memory level 13.0 , will exec 0.0 operations , has 178.0 bw with bridge , has 799591856.0 flops\n",
      "device 4 , has memory level 9.0 , will exec 0.0 operations , has 512.0 bw with bridge , has 765408594.0 flops\n",
      "device 5 , has memory level 27.0 , will exec 0.0 operations , has 467.0 bw with bridge , has 788913761.0 flops\n",
      "device 6 , has memory level 26.0 , will exec 0.0 operations , has 221.0 bw with bridge , has 879990765.0 flops\n",
      "device 7 , has memory level 26.0 , will exec 0.0 operations , has 855.0 bw with bridge , has 428789547.0 flops\n",
      "device 8 , has memory level 11.0 , will exec 0.0 operations , has 265.0 bw with bridge , has 738697649.0 flops\n",
      "\n",
      " \n",
      "will place 3.0 now , requires 25088.0 flops , will tranx 25088.0 data , requires 8.0 level memory\n",
      "device 0 , has memory level 18.0 , will exec 1.0 operations , has 214.0 bw with bridge , has 898887170.0 flops\n",
      "device 1 , has memory level 0.0 , will exec 1.0 operations , has 129.0 bw with bridge , has 566135391.0 flops\n",
      "device 2 , has memory level 19.0 , will exec 1.0 operations , has 233.0 bw with bridge , has 388634270.0 flops\n",
      "device 3 , has memory level 13.0 , will exec 0.0 operations , has 178.0 bw with bridge , has 799591856.0 flops\n",
      "device 4 , has memory level 9.0 , will exec 0.0 operations , has 512.0 bw with bridge , has 765408594.0 flops\n",
      "device 5 , has memory level 27.0 , will exec 0.0 operations , has 467.0 bw with bridge , has 788913761.0 flops\n",
      "device 6 , has memory level 26.0 , will exec 0.0 operations , has 221.0 bw with bridge , has 879990765.0 flops\n",
      "device 7 , has memory level 26.0 , will exec 0.0 operations , has 855.0 bw with bridge , has 428789547.0 flops\n",
      "device 8 , has memory level 11.0 , will exec 0.0 operations , has 265.0 bw with bridge , has 738697649.0 flops\n",
      "\n",
      " \n",
      "will place 4.0 now , requires 25088.0 flops , will tranx 25088.0 data , requires 9.0 level memory\n",
      "device 0 , has memory level 18.0 , will exec 1.0 operations , has 214.0 bw with bridge , has 898887170.0 flops\n",
      "device 1 , has memory level 0.0 , will exec 1.0 operations , has 129.0 bw with bridge , has 566135391.0 flops\n",
      "device 2 , has memory level 19.0 , will exec 1.0 operations , has 233.0 bw with bridge , has 388634270.0 flops\n",
      "device 3 , has memory level 6.0 , will exec 1.0 operations , has 178.0 bw with bridge , has 799591856.0 flops\n",
      "device 4 , has memory level 9.0 , will exec 0.0 operations , has 512.0 bw with bridge , has 765408594.0 flops\n",
      "device 5 , has memory level 27.0 , will exec 0.0 operations , has 467.0 bw with bridge , has 788913761.0 flops\n",
      "device 6 , has memory level 26.0 , will exec 0.0 operations , has 221.0 bw with bridge , has 879990765.0 flops\n",
      "device 7 , has memory level 26.0 , will exec 0.0 operations , has 855.0 bw with bridge , has 428789547.0 flops\n",
      "device 8 , has memory level 11.0 , will exec 0.0 operations , has 265.0 bw with bridge , has 738697649.0 flops\n",
      "\n",
      " \n",
      "will place 5.0 now , requires 25088.0 flops , will tranx 6272.0 data , requires 2.0 level memory\n",
      "device 0 , has memory level 18.0 , will exec 1.0 operations , has 214.0 bw with bridge , has 898887170.0 flops\n",
      "device 1 , has memory level 0.0 , will exec 1.0 operations , has 129.0 bw with bridge , has 566135391.0 flops\n",
      "device 2 , has memory level 19.0 , will exec 1.0 operations , has 233.0 bw with bridge , has 388634270.0 flops\n",
      "device 3 , has memory level 6.0 , will exec 1.0 operations , has 178.0 bw with bridge , has 799591856.0 flops\n",
      "device 4 , has memory level 1.0 , will exec 1.0 operations , has 512.0 bw with bridge , has 765408594.0 flops\n",
      "device 5 , has memory level 27.0 , will exec 0.0 operations , has 467.0 bw with bridge , has 788913761.0 flops\n",
      "device 6 , has memory level 26.0 , will exec 0.0 operations , has 221.0 bw with bridge , has 879990765.0 flops\n",
      "device 7 , has memory level 26.0 , will exec 0.0 operations , has 855.0 bw with bridge , has 428789547.0 flops\n",
      "device 8 , has memory level 11.0 , will exec 0.0 operations , has 265.0 bw with bridge , has 738697649.0 flops\n",
      "\n",
      " \n",
      "4096.0\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, comp_graph, device_graph):\n",
    "        \n",
    "        self.comp_graph, self.device_graph = comp_graph, device_graph \n",
    "        self.current_state = np.array([],np.float)\n",
    "        self.has_topo, self.topo_order = self.comp_graph.toposort()\n",
    "        print(self.topo_order)\n",
    "        self.available_mem = self.device_graph.device_memory\n",
    "        self.placement_dict = {}\n",
    "        \n",
    "        \n",
    "        self.valid_placements = 0\n",
    "        self.invalid_placements = 0\n",
    "        \n",
    "    def get_layer_tuple(self, layer_idx): #this idx is topo_sort[idx], from this we get \n",
    "        #layer_idx\n",
    "        #flop required\n",
    "        #data transfer\n",
    "        #required memory level\n",
    "        ##number of neighbors\n",
    "        return [\n",
    "            layer_idx,self.comp_graph.layer_estimated_float_op[layer_idx],\n",
    "            self.comp_graph.layer_output_shape[layer_idx],self.comp_graph.get_mem_level(layer_idx)\n",
    "        ]\n",
    "\n",
    "    def get_edge_tuple(self, device_idx):\n",
    "\n",
    "        #current memory level of device\n",
    "        #number of operations incorporated\n",
    "        #bandwidth to bridge\n",
    "        #flops power\n",
    "        ##number of floating point operations performed\n",
    "        return [\n",
    "            self.device_graph.get_mem_level(device_idx),\n",
    "            0,\n",
    "            self.device_graph.bridge_bandwidth[device_idx],\n",
    "            self.device_graph.device_flops[device_idx]\n",
    "        ]\n",
    "\n",
    "\n",
    "    def print_current_state(self):\n",
    "        #state e ektai layer ... [0][1] to [0][3]\n",
    "        print(\"will place \"+str(self.current_state[0][0])+\" now\",end=' ')\n",
    "        print(\", requires \"+str(self.current_state[0][1])+\" flops\",end=' ')\n",
    "        print(\", will tranx \"+str(self.current_state[0][2])+\" data\",end=' ')\n",
    "        print(\", requires \"+str(self.current_state[0][3])+\" level memory\")\n",
    "        \n",
    "        #device related info\n",
    "\n",
    "        for i in range(1,1+len(self.device_graph.device_memory)):\n",
    "            print(\"device \"+str(i-1),end=' ')\n",
    "            print(\", has memory level \"+str(self.current_state[i][0]),end=' ')\n",
    "            print(\", will exec \"+str(self.current_state[i][1])+\" operations\",end=' ')\n",
    "            print(\", has \"+str(self.current_state[i][2])+\" bw with bridge\",end=' ')\n",
    "            print(\", has \"+str(self.current_state[i][3])+\" flops\")\n",
    "            \n",
    "        print('')\n",
    "\n",
    "        #print(self.current_state)\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        init_state = []\n",
    "        self.done = 0\n",
    "        \n",
    "        self.valid_placements = 0\n",
    "        self.invalid_placements = 0\n",
    "        \n",
    "        #for i in range(self.comp_graph.num_layers):\n",
    "        init_state.append(self.get_layer_tuple(self.topo_order[0][0]))\n",
    "\n",
    "        for i in range(len(self.device_graph.device_memory)):\n",
    "            init_state.append(self.get_edge_tuple(i))\n",
    "\n",
    "        np_init_state = np.array(init_state,np.float)\n",
    "\n",
    "        self.current_state = np_init_state\n",
    "        self.available_mem = self.device_graph.device_memory.copy() #eita reference e hocche na \n",
    "\n",
    "        return self.current_state\n",
    "    \n",
    "    def reset_device_graph(self, device_graph):\n",
    "        self.device_graph = device_graph\n",
    "        return self.reset()\n",
    "\n",
    "    def is_valid_placement(self): # need further edit\n",
    "        \n",
    "        d = len(self.device_graph.device_memory)\n",
    "\n",
    "        for i in range(1,1+d):\n",
    "            if(self.current_state[i][0]<=0):\n",
    "                return 0\n",
    "        return 1\n",
    "    \n",
    "    def evaluate_placement(self): #edit korte hobe\n",
    "        \n",
    "        l = self.comp_graph.num_layers\n",
    "        d = len(self.device_graph.device_memory)\n",
    "\n",
    "        topo_idx = [] #will contain the index of vertex v in topo_order\n",
    "        # original vertex list = {0,1,2,3,4}\n",
    "        # in topo order = {2,1,3,0,4}\n",
    "        # in topo idx = {3,1,0,2,4}\n",
    "        for i in range(len(self.topo_order)):\n",
    "            topo_idx.append(-1)\n",
    "\n",
    "        for i in range(len(self.topo_order)):\n",
    "            topo_idx[self.topo_order[i][0]] = i\n",
    "        \n",
    "        # if(self.is_valid_placement() == 0):\n",
    "        #     global INVALID\n",
    "        #     INVALID = INVALID + INVALID_INCR\n",
    "        #     return INVALID\n",
    "        \n",
    "        estimated_tx_time = 0.0\n",
    "        \n",
    "        for i in range(l): #topo_order er serial e jacche\n",
    "            \n",
    "            #because ith placmement directs the placement of the ith vertex in topo_sort\n",
    "            cur_device = int(self.placement_dict[self.topo_order[i][0]]) \n",
    "            \n",
    "            for u in self.comp_graph.adj_list[self.topo_order[i][0]]:\n",
    "                \n",
    "                nxt_device =  int(self.placement_dict[u]) #we need to get the index of u from topo_idx\n",
    "                payload = self.comp_graph.layer_output_shape[self.topo_order[i][0]]\n",
    "                \n",
    "                if(cur_device != nxt_device):\n",
    "                    estimated_tx_time = estimated_tx_time + \\\n",
    "                    (payload/self.device_graph.bridge_bandwidth[cur_device]) + \\\n",
    "                    (payload/self.device_graph.bridge_bandwidth[nxt_device])  \n",
    "        \n",
    "        estimated_ex_time= 0.0\n",
    "        \n",
    "\n",
    "        level_wise = []\n",
    "        #print(self.topo_order)\n",
    "        #print(level_wise)\n",
    "        for i in range(len(self.topo_order)+3):\n",
    "            level_wise.append([])\n",
    "        \n",
    "        for i in range(len(self.topo_order)):\n",
    "            #print(i)\n",
    "            level_wise[self.topo_order[i][1]].append(self.topo_order[i][0])\n",
    "        \n",
    "        for cur_level in range(len(level_wise)):\n",
    "            \n",
    "            device_time = []\n",
    "            \n",
    "            for i in range(len(self.device_graph.device_memory)):\n",
    "                device_time.append(0.0)\n",
    "            \n",
    "            for i in range(len(level_wise[cur_level])):\n",
    "                \n",
    "                cur_v = level_wise[cur_level][i]\n",
    "                cur_device = self.placement_dict[cur_v]\n",
    "\n",
    "                flop_req = self.comp_graph.layer_estimated_float_op[cur_v]\n",
    "                flops_got = self.device_graph.device_flops[cur_device]\n",
    "            \n",
    "                device_time[cur_device] = device_time[cur_device]+flop_req/flops_got\n",
    "            \n",
    "            estimated_ex_time = estimated_ex_time + max(device_time)\n",
    "\n",
    "        #estimated_energy_consumption = []\n",
    "\n",
    "        #for i in range(l,l+d):\n",
    "        #    estimated_energy_consumption.append(self.current_state[i][4])\n",
    "\n",
    "        #return (1.0-BETA)*(estimated_ex_time+estimated_tx_time)+ \\ \n",
    "            #BETA*(np.average(estimated_energy_consumption)+np.var(estimated_energy_consumption))\n",
    "#         return (1.0-BETA)*estimated_tx_time+BETA*estimated_ex_time\n",
    "#         return BETA*estimated_ex_time+BETA*estimated_tx_time\n",
    "        return estimated_tx_time + estimated_ex_time\n",
    "\n",
    "    def step(self, action): #action is the index of a device\n",
    "\n",
    "        l = self.comp_graph.num_layers\n",
    "        d = len(self.device_graph.device_memory)\n",
    "        reward = 0.0\n",
    "        \n",
    "        layer_processed = int(self.current_state[0][0])\n",
    "        #current memory level of device\n",
    "        #number of operations incorporated\n",
    "        #bandwidth to bridge\n",
    "        #flops power\n",
    "        self.available_mem[action] = self.available_mem[action] - \\\n",
    "            self.comp_graph.layer_estimated_mem[layer_processed]\n",
    "        self.current_state[action+1][0] = calc_level(self.available_mem[action])\n",
    "        self.current_state[action+1][1] = self.current_state[action+1][1] + 1\n",
    "\n",
    "        self.done = self.done+1\n",
    "        self.placement_dict[layer_processed] = action\n",
    "        \n",
    "        if self.done==l:\n",
    "\n",
    "            if self.is_valid_placement()==0:\n",
    "                self.invalid_placements += 1\n",
    "#                 print(f\"Finished with invalid placement\")\n",
    "#                 return self.current_state,self.placement_dict,-10,1\n",
    "                return self.current_state,self.placement_dict,-1 * self.invalid_placements,1\n",
    "#                 return self.current_state,self.placement_dict,0,1\n",
    "            else:\n",
    "                self.valid_placements += 1\n",
    "                cost = self.evaluate_placement()\n",
    "                reward = 1.0/math.sqrt(cost)\n",
    "                #return self.current_state,self.placement_dict,10*reward,1\n",
    "                print(f\"Finished with correct placement, reward={reward}, evaluation={cost}\")\n",
    "#                 print(reward)\n",
    "#                 return self.current_state,self.placement_dict,100*reward,1\n",
    "                return self.current_state,self.placement_dict,reward,1\n",
    "        else:\n",
    "            estimated_tx_time = 0.0\n",
    "            \n",
    "            for u in self.comp_graph.rev_adj_list[layer_processed]:\n",
    "                \n",
    "                prev_device =  int(self.placement_dict[u]) #we need to get the index of u from topo_idx\n",
    "                payload = self.comp_graph.layer_output_shape[u]\n",
    "                \n",
    "                if(action != prev_device):\n",
    "                    estimated_tx_time = estimated_tx_time + \\\n",
    "                    (payload/self.device_graph.bridge_bandwidth[prev_device]) + \\\n",
    "                    (payload/self.device_graph.bridge_bandwidth[action])  \n",
    "            \n",
    "            # Why?\n",
    "            if(estimated_tx_time<=0.0):\n",
    "                reward = 3\n",
    "            else:\n",
    "                reward = 1.0/math.sqrt(estimated_tx_time)\n",
    "            \n",
    "            self.current_state[0] = self.get_layer_tuple(self.topo_order[self.done][0])\n",
    "            \n",
    "            \n",
    "            ### REWARD FUNCTION?\n",
    "            \n",
    "#             print(f\"REWARD: {reward}\")\n",
    "            \n",
    "            \n",
    "            if (self.available_mem[action]<=0.0):\n",
    "                self.invalid_placements += 1\n",
    "#                 return self.current_state,self.placement_dict,0,0\n",
    "                return self.current_state,self.placement_dict,-5,0\n",
    "            else:\n",
    "                self.valid_placements += 1\n",
    "#                 print(reward)\n",
    "                return self.current_state,self.placement_dict,0,0\n",
    "#                 return self.current_state,self.placement_dict,10*reward,0\n",
    "#                 return self.current_state,self.placement_dict,0,0\n",
    "\n",
    "\n",
    "layer_file = \"ml_graph_vgg.txt\"\n",
    "mem_file = \"vgg_new_memory_calc.txt\"\n",
    "\n",
    "c = Computation_Graph(layer_file,mem_file)\n",
    "#c.print_info()\n",
    "\n",
    "device_file = \"dev_graph.txt\"\n",
    "d = Device_Graph(device_file)\n",
    "d2 = Device_Graph(\"dev_graph_2.txt\")\n",
    "d3 = Device_Graph(\"dev_graph_3.txt\")\n",
    "d4 = Device_Graph(\"dev_graph_4.txt\")\n",
    "d5 = Device_Graph(\"dev_graph_5.txt\")\n",
    "d6 = Device_Graph(\"dev_graph_6.txt\")\n",
    "d7 = Device_Graph(\"dev_graph_7.txt\")\n",
    "\n",
    "devices = [d, d2, d3, d4, d5, d6, d7]\n",
    "#d.print_info()\n",
    "\n",
    "#c.check_topo_sort()\n",
    "\n",
    "\n",
    "e = Environment(c,d3)\n",
    "\n",
    "cur_state = e.reset()\n",
    "e.print_current_state()\n",
    "\n",
    "for i in range(0,5):\n",
    "    e.step(i)\n",
    "    e.print_current_state()\n",
    "    print(' ')\n",
    "\n",
    "print(MAX_MEMORY)\n",
    "print(MEMORY_LEVELS)\n",
    "\n",
    "# # for i in range(0,18):\n",
    "# #     e.step(0)\n",
    "# #     e.print_current_state()\n",
    "# #     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    #num_inputs = size of state vectors == number of operations\n",
    "    #num_actions = size of edge devices == number of actions\n",
    "    \n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, learning_rate=3e-4):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "\n",
    "        self.num_actions = num_actions\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size) #two layer NN as policy network\n",
    "        #self.linear3 = nn.Linear(32,16)\n",
    "        #self.linear4 = nn.Linear(16,16)\n",
    "        self.linear5 = nn.Linear(hidden_size,hidden_size*2)\n",
    "#         self.linear8 = nn.Linear(hidden_size*2,hidden_size*2)\n",
    "        self.linear6 = nn.Linear(hidden_size*2,hidden_size)\n",
    "        #self.linear7 = nn.Linear(64,32)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_actions)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        #x = F.relu(self.linear3(x))\n",
    "        #x = F.relu(self.linear4(x))\n",
    "        x = F.relu(self.linear5(x))\n",
    "#         x = F.relu(self.linear8(x))\n",
    "        x = F.relu(self.linear6(x))\n",
    "        #x = F.relu(self.linear7(x))\n",
    "        x = F.softmax(self.linear2(x), dim=1)\n",
    "        return x \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        #print(state)\n",
    "        #print(self.linear1.weight.data)\n",
    "        #print(self.linear2.weight.data)\n",
    "        probs = self.forward(Variable(state))\n",
    "        #print(probs)\n",
    "        #print(np.squeeze(probs.detach().numpy()))\n",
    "        highest_prob_action = np.random.choice(self.num_actions, p=np.squeeze(probs.detach().numpy()))\n",
    "        #print(highest_prob_action)\n",
    "        log_prob = torch.log(probs.squeeze(0)[highest_prob_action])\n",
    "        \n",
    "        return highest_prob_action, log_prob\n",
    "\n",
    "def update_policy(policy_network, rewards, log_probs):\n",
    "    \n",
    "    discounted_rewards = []\n",
    "    #print(rewards)\n",
    "    for t in range(len(rewards)):\n",
    "        Gt = 0 \n",
    "        pw = 0\n",
    "        for r in rewards[t:]:\n",
    "            Gt = Gt + GAMMA**pw * r\n",
    "            pw = pw + 1\n",
    "        discounted_rewards.append(Gt)\n",
    "    \n",
    "    discounted_rewards = torch.tensor(discounted_rewards)\n",
    "#     discounted_rewards = torch.tensor(rewards)\n",
    "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9) \n",
    "    #print(discounted_rewards)\n",
    "    \n",
    "    policy_gradient = []\n",
    "    for log_prob, Gt in zip(log_probs, discounted_rewards):\n",
    "        policy_gradient.append(-log_prob * Gt)\n",
    "    \n",
    "    policy_network.optimizer.zero_grad()\n",
    "    policy_gradient = torch.stack(policy_gradient).sum()\n",
    "    policy_gradient.backward()\n",
    "    policy_network.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def main(placement_environment, devices):\n",
    "    env = placement_environment\n",
    "    #v = env.op_graph.toposort()\n",
    "    layer_num = env.comp_graph.num_layers\n",
    "    device_num = len(env.device_graph.device_memory)\n",
    "\n",
    "    inp_size_nn = (1+device_num)*4\n",
    "    policy_net = PolicyNetwork(inp_size_nn, device_num, 64) #all 3 arguments are int\n",
    "\n",
    "    \n",
    "    converge = 0\n",
    "    max_epoch = 100000\n",
    "    best_state = {}\n",
    "    best_reward = 0.0\n",
    "    best_policy = copy.deepcopy(policy_net)\n",
    "    \n",
    "    best_success_rate = 0.0\n",
    "    \n",
    "    total_score = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    ok_count = 0\n",
    "    \n",
    "#     devices_idx = 0\n",
    "    device_successes = {d.filename: 0 for d in devices}\n",
    "    device_placements = {d.filename: 0 for d in devices}\n",
    "    \n",
    "    \n",
    "    while converge<max_epoch:\n",
    "        \n",
    "        # TODO(brian): swap in new/random device_graph here?\n",
    "#         state = env.reset()  #state has been made compatible\n",
    "        state = env.reset_device_graph(random.choice(devices))\n",
    "#         devices_idx = (devices_idx + 1) % len(devices)\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        \n",
    "        if converge%5000==0:\n",
    "            print(converge)\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            temp_state = state.copy()\n",
    "\n",
    "            for p in range(4):\n",
    "                temp_state[0][p] = float(temp_state[0][p])/MAX_OP_PARAM[p]\n",
    "\n",
    "            for d in range(1,1+device_num):\n",
    "                for p in range(4):\n",
    "                    temp_state[d][p] = float(temp_state[d][p])/MAX_ED_PARAM[p]\n",
    "\n",
    "            #network_state = temp_state.flatten()\n",
    "            #env.print_current_state()\n",
    "            #inp = (network_state-np.min(network_state))/np.ptp(network_state)\n",
    "            #inp = network_state\n",
    "            #val = np.array([np.sum(inp)/2000000000.0,np.sum(inp)/3000000000.0])\n",
    "            #print(val)\n",
    "            #print(inp)\n",
    "            action, log_prob = policy_net.get_action(temp_state.flatten())\n",
    "            #print(action)\n",
    "            #print(log_prob)\n",
    "            #print('action chosen '+str(action))\n",
    "            new_state, mapping, reward, done = env.step(action)\n",
    "            #env.print_current_state()\n",
    "            log_probs.append(log_prob)\n",
    "            rewards.append(reward)\n",
    "            \n",
    "            if done:\n",
    "                \n",
    "                #for i in range(layer_num):\n",
    "                #    print(state[i][0], end = \" \")\n",
    "                #print('')\n",
    "\n",
    "                converge += 1\n",
    "                score = env.evaluate_placement()\n",
    "                device_placements[env.device_graph.filename] += 1\n",
    "                if env.valid_placements == env.comp_graph.num_layers:\n",
    "                    total_score += score\n",
    "                    total_count += 1\n",
    "                    ok_count += 1\n",
    "                    \n",
    "                    device_successes[env.device_graph.filename] += 1\n",
    "                \n",
    "                # number of good rewards\n",
    "                pos = [num for num in rewards if num>0.0]\n",
    "                \n",
    "                log_frequency = 100\n",
    "                if converge%log_frequency==0:\n",
    "#                     print(f\"{converge}: pos={len(pos)}/{len(rewards)}, reward={reward}, evaluation={score}\")\n",
    "                    print(f\"{converge}:\")\n",
    "                    print(f\"\\tpos={env.valid_placements}/{len(rewards)}\")\n",
    "                    print(f\"\\treward={reward}\")\n",
    "                    print(f\"\\tevaluation={score}\")\n",
    "                    print(f\"\\tgraph={env.device_graph.filename}\")\n",
    "#                     print(env.valid_placements)\n",
    "#                     print(env.invalid_placements)\n",
    "                    rolling_success_rate = ok_count / log_frequency\n",
    "                    print(f\"\\tsuccess rate: {rolling_success_rate}%\")\n",
    "                    if total_count > 0:\n",
    "                        print(f\"\\trolling average score of ok = {total_score / total_count}\")\n",
    "                    if total_count > 100:\n",
    "                        total_score = 0\n",
    "                        total_count = 0\n",
    "                    ok_count = 0\n",
    "                    \n",
    "                    print(\"\\tdevice graph success rates\")\n",
    "                    for name, successes in device_successes.items():\n",
    "                        print(f\"\\t\\t{name}: {successes/device_placements[name]}%\")\n",
    "                        device_successes[name] = 0\n",
    "                        device_placements[name] = 0\n",
    "                    \n",
    "                    if rolling_success_rate > best_success_rate:\n",
    "                        best_success_rate = rolling_success_rate\n",
    "                        best_state = mapping\n",
    "                        best_policy = copy.deepcopy(policy_net)\n",
    "                        torch.save(best_policy.state_dict(), './mymodel.pt')\n",
    "                        print(\"\\tcurrent best state \")\n",
    "                        print(\"\\t\", best_state)          \n",
    "                    \n",
    "                    print(best_policy.linear1.weight.data)\n",
    "                \n",
    "                update_policy(policy_net, rewards, log_probs)\n",
    "                \n",
    "#                 if len(pos) > best_reward:\n",
    "#                     best_reward = len(pos)\n",
    "#                     best_state = mapping\n",
    "#                     best_policy = copy.deepcopy(policy_net)\n",
    "#                     torch.save(best_policy.state_dict(), './mymodel.pt')\n",
    "#                     print(\"current best state \")\n",
    "#                     print(best_state)          \n",
    "\n",
    "\n",
    "\n",
    "                #if converge%1000==0:\n",
    "                #print(\"state \"+str(state))\n",
    "                #print(\"reward incurred \"+str(reward))\n",
    "                break\n",
    "            \n",
    "            state = new_state\n",
    "    \n",
    "\n",
    "      \n",
    "    return best_state,best_reward, best_policy, inp_size_nn, device_num \n",
    "\n",
    "# print(\"hello\")\n",
    "\n",
    "myenv = e\n",
    "\n",
    "def set_MAX_PARAMS(environment):\n",
    "    #layer_idx         \n",
    "        #flop required\n",
    "        #data transfer\n",
    "        #required memory level\n",
    "    MAX_OP_PARAM[0] = float(len(environment.comp_graph.layer_estimated_mem))\n",
    "    MAX_OP_PARAM[1] = float(max(environment.comp_graph.layer_estimated_float_op))\n",
    "    MAX_OP_PARAM[2] = float(max(environment.comp_graph.layer_output_shape))\n",
    "    MAX_OP_PARAM[3] = float(MEMORY_LEVELS + 1)\n",
    "    #current memory level of device\n",
    "        #number of operations incorporated\n",
    "        #bandwidth to bridge\n",
    "        #flops power\n",
    "\n",
    "    MAX_ED_PARAM[0] = float(MEMORY_LEVELS + 1)\n",
    "    MAX_ED_PARAM[1] = float(environment.comp_graph.num_layers)\n",
    "    MAX_ED_PARAM[2] = float(max(environment.device_graph.bridge_bandwidth))\n",
    "    MAX_ED_PARAM[3] = float(max(environment.device_graph.device_flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Finished with correct placement, reward=0.024293979601750774, evaluation=1694.3482366073258\n",
      "Finished with correct placement, reward=0.03055435041914235, evaluation=1071.158873284928\n",
      "100:\n",
      "\tpos=18/22\n",
      "\treward=-4\n",
      "\tevaluation=1223.006521566016\n",
      "\tgraph=dev_graph_5.txt\n",
      "\tsuccess rate: 0.02%\n",
      "\trolling average score of ok = 1382.7535549461268\n",
      "\tdevice graph success rates\n",
      "\t\tdev_graph.txt: 0.0%\n",
      "\t\tdev_graph_2.txt: 0.0%\n",
      "\t\tdev_graph_3.txt: 0.05555555555555555%\n",
      "\t\tdev_graph_4.txt: 0.09090909090909091%\n",
      "\t\tdev_graph_5.txt: 0.0%\n",
      "\t\tdev_graph_6.txt: 0.0%\n",
      "\t\tdev_graph_7.txt: 0.0%\n",
      "\tcurrent best state \n",
      "\t {0: 0, 1: 0, 2: 6, 3: 4, 4: 5, 5: 2, 6: 2, 7: 8, 8: 3, 9: 5, 10: 7, 11: 7, 12: 1, 13: 6, 14: 1, 15: 4, 16: 5, 17: 5, 18: 1, 19: 3, 20: 8, 21: 3}\n",
      "tensor([[ 0.0495, -0.1079,  0.0237,  ...,  0.1101,  0.1295,  0.1123],\n",
      "        [ 0.1154, -0.0712,  0.0546,  ..., -0.1004,  0.1219,  0.0524],\n",
      "        [-0.1361, -0.0961,  0.1214,  ...,  0.0880,  0.1184, -0.1251],\n",
      "        ...,\n",
      "        [ 0.0838, -0.1502, -0.0584,  ..., -0.0841, -0.1220,  0.1277],\n",
      "        [ 0.1248,  0.1298, -0.0399,  ..., -0.0628,  0.0376,  0.0920],\n",
      "        [ 0.1534, -0.1120,  0.1070,  ..., -0.1113, -0.1396,  0.1177]])\n",
      "Finished with correct placement, reward=0.03515102644480592, evaluation=809.3269032905114\n",
      "Finished with correct placement, reward=0.04209999875897935, evaluation=564.2035753329383\n",
      "Finished with correct placement, reward=0.02623092510263068, evaluation=1453.3586012391615\n",
      "200:\n",
      "\tpos=16/22\n",
      "\treward=-6\n",
      "\tevaluation=3323.29485611073\n",
      "\tgraph=dev_graph.txt\n",
      "\tsuccess rate: 0.03%\n",
      "\trolling average score of ok = 1118.479237950973\n",
      "\tdevice graph success rates\n",
      "\t\tdev_graph.txt: 0.0%\n",
      "\t\tdev_graph_2.txt: 0.0%\n",
      "\t\tdev_graph_3.txt: 0.05%\n",
      "\t\tdev_graph_4.txt: 0.0%\n",
      "\t\tdev_graph_5.txt: 0.07692307692307693%\n",
      "\t\tdev_graph_6.txt: 0.0625%\n",
      "\t\tdev_graph_7.txt: 0.0%\n",
      "\tcurrent best state \n",
      "\t {0: 6, 1: 5, 2: 0, 3: 8, 4: 0, 5: 1, 6: 4, 7: 3, 8: 5, 9: 7, 10: 2, 11: 2, 12: 6, 13: 6, 14: 6, 15: 3, 16: 3, 17: 3, 18: 2, 19: 1, 20: 5, 21: 5}\n",
      "tensor([[ 0.0462, -0.1111,  0.0198,  ...,  0.1081,  0.1275,  0.1089],\n",
      "        [ 0.1178, -0.0705,  0.0540,  ..., -0.1017,  0.1254,  0.0568],\n",
      "        [-0.1283, -0.0945,  0.1164,  ...,  0.0920,  0.1206, -0.1226],\n",
      "        ...,\n",
      "        [ 0.0811, -0.1509, -0.0554,  ..., -0.0858, -0.1243,  0.1251],\n",
      "        [ 0.1272,  0.1321, -0.0379,  ..., -0.0610,  0.0400,  0.0943],\n",
      "        [ 0.1556, -0.1080,  0.1100,  ..., -0.1132, -0.1384,  0.1203]])\n",
      "Finished with correct placement, reward=0.024963531190484094, evaluation=1604.6782417218164\n",
      "Finished with correct placement, reward=0.029571463738987787, evaluation=1143.5478880388544\n",
      "Finished with correct placement, reward=0.036451380903375845, evaluation=752.6135428565092\n",
      "Finished with correct placement, reward=0.030380754470651763, evaluation=1083.4350725202823\n",
      "Finished with correct placement, reward=0.03606822537054449, evaluation=768.6886182450874\n",
      "Finished with correct placement, reward=0.027769600077465217, evaluation=1296.7634146757491\n",
      "Finished with correct placement, reward=0.029241108344589293, evaluation=1169.5326218449954\n",
      "Finished with correct placement, reward=0.029182799664047517, evaluation=1174.2108591777219\n",
      "300:\n",
      "\tpos=18/22\n",
      "\treward=-4\n",
      "\tevaluation=1379.7416514258416\n",
      "\tgraph=dev_graph_4.txt\n",
      "\tsuccess rate: 0.08%\n",
      "\trolling average score of ok = 1121.989726833529\n",
      "\tdevice graph success rates\n",
      "\t\tdev_graph.txt: 0.0%\n",
      "\t\tdev_graph_2.txt: 0.0%\n",
      "\t\tdev_graph_3.txt: 0.0%\n",
      "\t\tdev_graph_4.txt: 0.23076923076923078%\n",
      "\t\tdev_graph_5.txt: 0.1%\n",
      "\t\tdev_graph_6.txt: 0.17391304347826086%\n",
      "\t\tdev_graph_7.txt: 0.0%\n",
      "\tcurrent best state \n",
      "\t {0: 8, 1: 2, 2: 7, 3: 4, 4: 0, 5: 4, 6: 8, 7: 4, 8: 1, 9: 4, 10: 7, 11: 1, 12: 5, 13: 8, 14: 1, 15: 4, 16: 1, 17: 8, 18: 8, 19: 5, 20: 3, 21: 4}\n",
      "tensor([[ 0.0438, -0.1140,  0.0180,  ...,  0.1049,  0.1278,  0.1071],\n",
      "        [ 0.1137, -0.0696,  0.0649,  ..., -0.1037,  0.1278,  0.0591],\n",
      "        [-0.1260, -0.0900,  0.1157,  ...,  0.0963,  0.1198, -0.1216],\n",
      "        ...,\n",
      "        [ 0.0801, -0.1470, -0.0569,  ..., -0.0845, -0.1258,  0.1237],\n",
      "        [ 0.1295,  0.1346, -0.0343,  ..., -0.0605,  0.0419,  0.0970],\n",
      "        [ 0.1540, -0.1084,  0.1167,  ..., -0.1147, -0.1375,  0.1223]])\n",
      "Finished with correct placement, reward=0.025386382144012006, evaluation=1551.6664626875763\n",
      "Finished with correct placement, reward=0.031161284969779095, evaluation=1029.8388802686886\n",
      "Finished with correct placement, reward=0.03644615392310543, evaluation=752.8294327548446\n",
      "400:\n",
      "\tpos=18/22\n",
      "\treward=-4\n",
      "\tevaluation=646.9061241771511\n",
      "\tgraph=dev_graph_2.txt\n",
      "\tsuccess rate: 0.03%\n",
      "\trolling average score of ok = 1120.0125765341866\n",
      "\tdevice graph success rates\n",
      "\t\tdev_graph.txt: 0.0%\n",
      "\t\tdev_graph_2.txt: 0.0%\n",
      "\t\tdev_graph_3.txt: 0.09090909090909091%\n",
      "\t\tdev_graph_4.txt: 0.0%\n",
      "\t\tdev_graph_5.txt: 0.0%\n",
      "\t\tdev_graph_6.txt: 0.14285714285714285%\n",
      "\t\tdev_graph_7.txt: 0.0%\n",
      "tensor([[ 0.0438, -0.1140,  0.0180,  ...,  0.1049,  0.1278,  0.1071],\n",
      "        [ 0.1137, -0.0696,  0.0649,  ..., -0.1037,  0.1278,  0.0591],\n",
      "        [-0.1260, -0.0900,  0.1157,  ...,  0.0963,  0.1198, -0.1216],\n",
      "        ...,\n",
      "        [ 0.0801, -0.1470, -0.0569,  ..., -0.0845, -0.1258,  0.1237],\n",
      "        [ 0.1295,  0.1346, -0.0343,  ..., -0.0605,  0.0419,  0.0970],\n",
      "        [ 0.1540, -0.1084,  0.1167,  ..., -0.1147, -0.1375,  0.1223]])\n",
      "Finished with correct placement, reward=0.0348088886112072, evaluation=825.3148995299363\n",
      "Finished with correct placement, reward=0.03977085232173792, evaluation=632.2228719280445\n",
      "Finished with correct placement, reward=0.02584699243679252, evaluation=1496.8558138858339\n",
      "Finished with correct placement, reward=0.039645825583215215, evaluation=636.2167048211375\n",
      "500:\n",
      "\tpos=19/22\n",
      "\treward=-3\n",
      "\tevaluation=990.7548665535304\n",
      "\tgraph=dev_graph_2.txt\n",
      "\tsuccess rate: 0.04%\n",
      "\trolling average score of ok = 1075.540575735597\n",
      "\tdevice graph success rates\n",
      "\t\tdev_graph.txt: 0.0%\n",
      "\t\tdev_graph_2.txt: 0.0%\n",
      "\t\tdev_graph_3.txt: 0.0%\n",
      "\t\tdev_graph_4.txt: 0.1111111111111111%\n",
      "\t\tdev_graph_5.txt: 0.17647058823529413%\n",
      "\t\tdev_graph_6.txt: 0.0%\n",
      "\t\tdev_graph_7.txt: 0.0%\n",
      "tensor([[ 0.0438, -0.1140,  0.0180,  ...,  0.1049,  0.1278,  0.1071],\n",
      "        [ 0.1137, -0.0696,  0.0649,  ..., -0.1037,  0.1278,  0.0591],\n",
      "        [-0.1260, -0.0900,  0.1157,  ...,  0.0963,  0.1198, -0.1216],\n",
      "        ...,\n",
      "        [ 0.0801, -0.1470, -0.0569,  ..., -0.0845, -0.1258,  0.1237],\n",
      "        [ 0.1295,  0.1346, -0.0343,  ..., -0.0605,  0.0419,  0.0970],\n",
      "        [ 0.1540, -0.1084,  0.1167,  ..., -0.1147, -0.1375,  0.1223]])\n",
      "Finished with correct placement, reward=0.04355816984466156, evaluation=527.0608426207881\n",
      "Finished with correct placement, reward=0.02992429445866082, evaluation=1116.7402277812487\n",
      "Finished with correct placement, reward=0.032468693602752494, evaluation=948.5721512819167\n",
      "600:\n",
      "\tpos=22/22\n",
      "\treward=0.032468693602752494\n",
      "\tevaluation=948.5721512819167\n",
      "\tgraph=dev_graph_6.txt\n",
      "\tsuccess rate: 0.03%\n",
      "\trolling average score of ok = 1047.964553756343\n",
      "\tdevice graph success rates\n",
      "\t\tdev_graph.txt: 0.0%\n",
      "\t\tdev_graph_2.txt: 0.0%\n",
      "\t\tdev_graph_3.txt: 0.0%\n",
      "\t\tdev_graph_4.txt: 0.0%\n",
      "\t\tdev_graph_5.txt: 0.05555555555555555%\n",
      "\t\tdev_graph_6.txt: 0.1111111111111111%\n",
      "\t\tdev_graph_7.txt: 0.0%\n",
      "tensor([[ 0.0438, -0.1140,  0.0180,  ...,  0.1049,  0.1278,  0.1071],\n",
      "        [ 0.1137, -0.0696,  0.0649,  ..., -0.1037,  0.1278,  0.0591],\n",
      "        [-0.1260, -0.0900,  0.1157,  ...,  0.0963,  0.1198, -0.1216],\n",
      "        ...,\n",
      "        [ 0.0801, -0.1470, -0.0569,  ..., -0.0845, -0.1258,  0.1237],\n",
      "        [ 0.1295,  0.1346, -0.0343,  ..., -0.0605,  0.0419,  0.0970],\n",
      "        [ 0.1540, -0.1084,  0.1167,  ..., -0.1147, -0.1375,  0.1223]])\n",
      "Finished with correct placement, reward=0.039387007289740074, evaluation=644.6055391896284\n",
      "Finished with correct placement, reward=0.038621403354759706, evaluation=670.4152726164648\n",
      "Finished with correct placement, reward=0.0339716406227658, evaluation=866.4967890566961\n",
      "Finished with correct placement, reward=0.03171007491867518, evaluation=994.5015487714937\n",
      "Finished with correct placement, reward=0.029444655729577142, evaluation=1153.4188329744557\n",
      "Finished with correct placement, reward=0.033208228778754165, evaluation=906.7938694581838\n",
      "Finished with correct placement, reward=0.02651253050278243, evaluation=1422.648589552362\n",
      "700:\n",
      "\tpos=15/22\n",
      "\treward=-7\n",
      "\tevaluation=1225.100147737202\n",
      "\tgraph=dev_graph_2.txt\n",
      "\tsuccess rate: 0.07%\n",
      "\trolling average score of ok = 1025.402172600506\n",
      "\tdevice graph success rates\n",
      "\t\tdev_graph.txt: 0.0%\n",
      "\t\tdev_graph_2.txt: 0.0%\n",
      "\t\tdev_graph_3.txt: 0.07142857142857142%\n",
      "\t\tdev_graph_4.txt: 0.0%\n",
      "\t\tdev_graph_5.txt: 0.1%\n",
      "\t\tdev_graph_6.txt: 0.2222222222222222%\n",
      "\t\tdev_graph_7.txt: 0.0%\n",
      "tensor([[ 0.0438, -0.1140,  0.0180,  ...,  0.1049,  0.1278,  0.1071],\n",
      "        [ 0.1137, -0.0696,  0.0649,  ..., -0.1037,  0.1278,  0.0591],\n",
      "        [-0.1260, -0.0900,  0.1157,  ...,  0.0963,  0.1198, -0.1216],\n",
      "        ...,\n",
      "        [ 0.0801, -0.1470, -0.0569,  ..., -0.0845, -0.1258,  0.1237],\n",
      "        [ 0.1295,  0.1346, -0.0343,  ..., -0.0605,  0.0419,  0.0970],\n",
      "        [ 0.1540, -0.1084,  0.1167,  ..., -0.1147, -0.1375,  0.1223]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with correct placement, reward=0.015447089182713881, evaluation=4190.894152092443\n",
      "Finished with correct placement, reward=0.033315053672555835, evaluation=900.9879142508726\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b92152bc6cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mset_MAX_PARAMS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8cbe075be931>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(placement_environment, devices)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m#print(val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m#print(inp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;31m#print(action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m#print(log_prob)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8520cb293c24>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#print(self.linear1.weight.data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#print(self.linear2.weight.data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m#print(probs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(np.squeeze(probs.detach().numpy()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8520cb293c24>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#x = F.relu(self.linear7(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brian/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_MAX_PARAMS(e)\n",
    "\n",
    "best_state,best_reward, best_policy, inp_size, device_num = main(e, devices)\n",
    "print(\"training complete\")\n",
    "\n",
    "print(\"best state \"+str(best_state))\n",
    "print(\"estimated computation time \"+str(1.0/best_reward**2)+\" second\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(best_policy.linear1.weight.data)\n",
    "print(best_policy.num_actions)\n",
    "\n",
    "layer_file = \"ml_graph_vgg.txt\"\n",
    "mem_file = \"vgg_new_memory_calc.txt\"\n",
    "\n",
    "c = Computation_Graph(layer_file,mem_file)\n",
    "\n",
    "\n",
    "device_file = \"dev_graph.txt\"\n",
    "d = Device_Graph(device_file)\n",
    "#d.print_info()\n",
    "\n",
    "#c.check_topo_sort()\n",
    "\n",
    "\n",
    "e_another = Environment(c,d)\n",
    "\n",
    "cur_state = e_another.reset()\n",
    "#e_another.print_current_state()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,22):\n",
    "    print(i)\n",
    "    temp_state = cur_state.copy()\n",
    "\n",
    "    for p in range(4):\n",
    "        temp_state[0][p] = float(temp_state[0][p])/MAX_OP_PARAM[p]\n",
    "\n",
    "    for d in range(1,1+device_num):\n",
    "        for p in range(4):\n",
    "            temp_state[d][p] = float(temp_state[d][p])/MAX_ED_PARAM[p]\n",
    "\n",
    "    action, log_prob = best_policy.get_action(temp_state.flatten())\n",
    "    #print(action)\n",
    "    cur_state, mapping, reward, done = e_another.step(action)\n",
    "    #e_another.print_current_state()\n",
    "\n",
    "#print(mapping)\n",
    "mapping_file = \"mapping_default.txt\"\n",
    "\n",
    "f = open(mapping_file,\"w\")\n",
    "\n",
    "for key in mapping:\n",
    "    f.write(c.layer_idx_to_name_map[key]+' '+str(mapping[key])+'\\n')\n",
    "f.close()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_graph(env, model, device_graph):\n",
    "    state = env.reset_device_graph(device_graph)\n",
    "    \n",
    "    for i in range(env.comp_graph.num_layers):\n",
    "        curr_state = state.copy()\n",
    "        \n",
    "        for p in range(4):\n",
    "            curr_state[0][p] = float(curr_state[0][p])/MAX_OP_PARAM[p]\n",
    "\n",
    "        for d in range(1,1+env.device_graph.num_devices):\n",
    "            for p in range(4):\n",
    "                curr_state[d][p] = float(curr_state[d][p])/MAX_ED_PARAM[p]\n",
    "        \n",
    "        action, log_prob = model.get_action(curr_state.flatten())\n",
    "        curr_state, mapping, reward, done = env.step(action)\n",
    "\n",
    "    if env.valid_placements == env.comp_graph.num_layers:\n",
    "        print(\"Good!\")\n",
    "        return True\n",
    "    print(\"Bad :(\")\n",
    "    return False\n",
    "\n",
    "import device_gen\n",
    "import os\n",
    "\n",
    "def validate(num_graphs=5, num_trials=100):\n",
    "    val_graph_files = [f'tmp_val_dev_graph_{i}.txt' for i in range(num_graphs)]\n",
    "    \n",
    "    for filename in val_graph_files:\n",
    "        print(filename)\n",
    "        device_gen.write_graph(9, [300000000, 1000000000], [1024, 4096], [50, 1000], filename=filename)\n",
    "    \n",
    "    val_device_graphs = [Device_Graph(file) for file in val_graph_files]\n",
    "\n",
    "    # Load best policy network\n",
    "    num_devices = len(val_device_graphs[0].device_memory)\n",
    "    nn_input_size = (num_devices + 1) * 4\n",
    "    model = PolicyNetwork(nn_input_size, num_devices, 64)\n",
    "    model.load_state_dict(torch.load('./mymodel.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Create compute graph\n",
    "    layer_file = \"ml_graph_vgg.txt\"\n",
    "    mem_file = \"vgg_new_memory_calc.txt\"\n",
    "    compute_graph = Computation_Graph(layer_file,mem_file)\n",
    "\n",
    "    # create Env\n",
    "    env = Environment(compute_graph, val_device_graphs[0])\n",
    "    \n",
    "    # Run trials\n",
    "    results = []\n",
    "    results_per_graph = {d.filename: 0 for d in val_device_graphs}\n",
    "    \n",
    "    for _ in range(num_trials):\n",
    "        for device_graph in val_device_graphs:\n",
    "            res = place_graph(env, policy_network, device_graph)\n",
    "            results_per_graph[device_graph.filename] += int(res)\n",
    "            results.append(res)\n",
    "    \n",
    "    print(\"Final percentage of valid placements: \", sum(results) / len(results))\n",
    "    print(\"Per device graph:\")\n",
    "    for name, count in results_per_graph.items():\n",
    "        print(f\"\\t{name}: {count / num_trials}%\")\n",
    "    \n",
    "    ## remove temp files\n",
    "    for file in val_graph_files:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-69bc4b4e8d91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-06dedc153af5>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(num_graphs, num_trials)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdevice_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m300000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000000000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mval_device_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDevice_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_graph_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Load best policy network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-06dedc153af5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdevice_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m300000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000000000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mval_device_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDevice_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_graph_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Load best policy network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-be26de12a8a6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfileReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdevice_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_val_dev_graph_0.txt\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
